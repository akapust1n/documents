\section*{Метод поиска аномалий на неразмеченных наборах данных}
\label{cha:analysis}
\textbf{Аннотация}: Проводится сравнительный анализ существующих методов поиска аномалий на неразмеченных наборах данных. Предлагается новый подход, основаный на ансамблировании нескольких метрических методов путем простого голосования показателей аномальности.В результате точность классификации повышается более чем на 30\% по сравнению с классическими метричеcкими методами.Даются рекомендации к использованию нового подхода в зависимости от цели поиска.
 
\textbf{Ключевые слова}: аномалия, ансамблирование, машинное обучение, метрические методы, бинарная классификация. 
\section{Введение} 
Задача поиска аномалий в виде выбросов является одной из классических задач машинного обучения. В настоящее время задачу поиска аномалий активно решают в различных областях деятельности: защита информации и безопастость, социальная сфера и медицина, банковская и финансовая отрасль, распознавание и обработка текста, изображений, речи и многих других.

Количество данных в мире удваивается примерно каждые два года. Поэтому актуальной задачей является разработка и совершенствование методов поиска выбросов.

\subsection{Классификация методов обнаружений аномалий}
Классическая система классификации предполагает предварительное обучение на обучающем наборе данных и последующую классификацию на основе этого набора. Данные делятся на "обучающую выборку"\ - данные, при помощи которых алогритм обучает классификатор и, "тестовую выборку"\ - данные, при анилизе которых классификатор остается неизменным. Тестовая выборка нужна для того чтобы проверить корректность обучения классификатора.

Однако в поиске аномалий возможны варианты, отличающиеся от классического. Подходящий метод классификации выбирается на основе наличия разметки данных.   Выделяются три основых типа методов:
\begin{enumerate}
	\item Обучение с учителем. Для обучения необходимо наличие полностью  размеченных данных для обучения и для тестов. Классификатор  обучается один раз и применяться впоследствии.В связи с тем, что для многих наборов данных заранее неизвестно, что является аномалией, а что нет, применение этого метода ограничено.
	\item Обучение с частичным привлечением учителя. Для обучения необходимо наличие тествого и учебного набора данных. Однако в отличие от обучения с привлечением учителя разметка данных не требуется. Все данные, представленные в выборках, считаются нормальными. На основе этих данных строится некая модель. Все данные, отклоняющиеся от этой модели, считаются аномальными.
	\item Обучение без учителя.
	Не требуется разметка набора данных.  Идея заключается в том, что алгоритм обнаружения аномалий оценивает данные исключительно на основе внутренних свойств набора данных что является нормальным, а что является выбросом. 
\end{enumerate}
Разметка наборов данных - нетривиальная задача, которая требует отдельного решения. Поэтому использование алгоритмов обучения без учителя является наиболее гибким подходом, который не требует трудозатрат на предварительную разметку данных. В данной работе основное внимание будет уделено именно этому типу методов.

\section{Основные классы методов поиска аномалий при обучении без учителя}
Задача поиска выбросов является задачей бинарной классификации, где в результе работы алгоритма поиска каждому элементу набора данных присваивается бинарная метка. Бинарная метка - показатель, который принимает нулевое значение в том случае, если она связана с нормальными данными, и единицу в противном случае. Присвоение этой метки происходит на основе анализа оценки достоверности(показателя аномальности) каждого элемента. Оценка показывает вероятность того, что элемент является аномалией. Для разных алгоритмов используются разные шкалы оценок, поэтому приведение конкретных примеров оценок будет некорректным.


\subsection{Вероятностно-генеративные методы}
Основная идея генеративных методов заключается в использовании вероятностного смесевого моделирования данных. Предлагается подобрать такую вероятностную модель, из которой были получены нормальные данные. Такие модели обычно называются генеративными моделями, где для каждой точки(элемента данных) можно посчитать генеративную вероятность(или вероятность правдоподобия).Т.е. задача  сводится к нахождению плотности распределения p(x). Аномалиями при этом  считаются точки(элементы набора данных), имеющию низкое правдоподобие. В качестве показателя аномальности выступает функция p.
Для построения генеративной модели нужно решить следующую задачу:
\begingroup
\Large
\begin{equation}
\prod \limits_{x \in X_{norm}} p(x,\theta)  \rightarrow max_\theta
\end{equation}
\endgroup
где \begingroup \Large$ X_{norm}$ \endgroup - нормальные элемента представленного набора данных, ${p(x,\theta)|\theta \in \omega}$ -семейство плотностей вероятностей, параметризованные $\theta$.

Этот метод редко используется на практике, так как тяжело проверить полученную генеративную модель на адекватность, сложно  убедится в правильном выборе семейства смесевых распределений. Это связано с тем, что низкое значение функции правдоподобия может означать как и аномальное значение, так и неудачно подобранную модель. Этот метод применяется с опорой на априорную информацию, в случае когда можно проверить полученную модель на адекватность.
\subsection{Линейные методы}
Основной идеей линейных методов является построение некой  модели, характеризующей нормальные данные. Точки, которые значительно отклоняются от этой модели, считаются аномалиями.

Предполагается, что нормальные данные  находятся в подпрострастрансве пространства атрибутов данных(размер подпространства атрибутов данных равен размерности данных). В свою очередь, задача линейного метода - найти низкоразмерные подпространства, такие что, выборка данных этого подпространства значительно отличается от остальных точек пространства данных.

Одним из возможных вариантов решения является использование линейной регрессии. Выбирается одна из наблюдаемых переменных  набора данных и относительно неё решается задача линейной регрессии оставшихся атрибутов. Итоговым ответом будет является усредненное значения показателя аномалии по всем атрибутам. 

Алгоритмы, основанные на линейном подходе, требуют  наличия линейной зависимости атрибутов данных. 
\subsection{Метрические методы}
Метрические методы пытаются найти в данных точки, в некотором смысле
изолированные от остальных\cite{Book01}. Если в пространстве задана некоторая метрика \textit{p(x1, x2)}, то необходимо задать следующие понятия:
\begin{itemize}
	\item  Аномалии – точки, не попадающие ни в один кластер. К данным применяется один из алгоритмов кластеризации; размер кластера, в котором оказалась точка, объявляется её показатель аномальности.
	\item Локальная плотность в аномальных точках низкая. Для данной точки показателем аномальности объявляется локальная плотность, которая оценивается некоторым непараметрическим способом.
	\item Расстояние от данной точки до ближайших соседей велико.
\end{itemize}
В качестве показателя аномальности может выступать:
\begin{itemize}
	\item расстояние до k-го ближайшего соседа;
	\item среднее расстояние до k ближайших соседей;
	\item медиана расстояний до k ближайших соседей;
	\item гармоническое среднее до k ближайших соседей;
	\item доля из k ближайших соседей, для которых данная точка является не
	более чем k-ым соседом и многое другое.
\end{itemize}

Метрические методы используют в случае отсутствия априорной информации о данных. Сложность вычисления прямо пропорциональна как размерности данных m, так и их количеству n. При росте набора данных наблюдается экспоненциальный рост сложности вычислений. Однако, эти методы хорошо проявляют себя на ограниченных наборах данных\cite{Book07}. Следовательно такие методы как k-ближайших соседей) с нотацией ассимптотического роста $O(n^2)$ недопустимы для наборов данных с большой размерностью, если их размерность не может быть уменьшена.
\subsection{Cравнение методов}
Исходя из характеристик вышеописанных методов, можно сделать вывод о том, что
метрические методы поиска аномалий обладают наибольшей универсальностью. Также
метрические методы легко совмещать за счёт единой методики измерения показателя
аномальности.Под универсальностью понимается возможность применять алгоритмы к различным набором данных, не обладающих специфическими характеристиками, и, не обладая априорной информацией, получать высокую точность классификации.

\begin{table}[!h]
	
	\caption{\label{tab:collectdata}Сравнение алгоритмов поиска аномалий}
	
	\begin{center}
		
		\begin{tabular}{|l|l|l|l|}
			
			\hline
			
			Класс методов & Временная сложность & Расход памяти & Универсальность \\
			
			\hline \hline
			
			Вероятностно-ген.& O(1) &  O(n) & Очень низкая \\
			
			
			\hline
			
			Линейный &  $\ge O(n^2)$ &  $\ge O(n^2)$ & Низкая\\
			
			
		
			\hline
			Метрический & $\ge O(nlogn)$ & $\ge O(n)$ & Высокая\\
			
			
			\hline
			
			
		\end{tabular}
		
	\end{center}
	
\end{table}                               



\section{Методы улучшения алгоритмов поиска аномалий}
Алгоритмы поиска аномалий можно улучшать различными методами, применяемыми в том числе для  улучшения результатов работы алгоритмов и в других областях. Например, ансамблирование широко применяется для работы с нейронными сетями. Ниже рассмотрены приемы в контексте поиска аномалий.
\subsection{Cемплирование}
Большинство алгоритмов распознавания аномалий успешно работают на наборах данных малых размеров. Поэтому предлагается разбить начальный набор данных на несколько случайных выборок и усреднить результат. Размер этих выборок может быть как и случайным, там и фиксированного размера, но, как правило, он отличается от размеров исходного набора данных не меньше чем на порядок. Идея такого выбора заключается в том, что шумовые объекты попадут в выборки с низкой вероятностью; кластера нормальных данных будут представлены несколькими представителями, а кластера аномалий выродятся в изолированные точки. На основе этих выборок алгоритмы строят функции показателя аномальности, незначительно уступующему результату, полученному на основе анализа всех исходных данных. 

Этот метод помогает значительно сократить вычислительную сложность, а так же уменьшить вероятность "подгона"\ алгоритма под конкретный набор данных.  В силу особенностей задачи, необходимое условие - отсутствия параметризации алгоритмов -  зачастую означает их детерминированность(в отсутсвии стохастичности, показатель аномальности однозначно определяется по  заданной выборке). В общем случае при добавлении новых данных в общий набор данных, можно не пересчитывать заново показатель аномальности для всего набора данных, а добавить запуски алгоритма на новых данных в ансамбль(так называемый warm start). \cite{Book15}
\subsection{Ансамблирование голосованием}
Ансамблированием в задаче поиска аномалий называют использование нескольких различных алгоритмов с последующи усреднением их показателя аномальности. При использовании различных классов алгоритмов можно столкнуться с проблемой того, что показатель аномальности выглядит по-разному в различных алгоритмах и сравнивать напрямую эти показатели некорректно.  Поэтому традиционное приведение  показателей значений различных функций к одному диапазону, например,к [0,1], будет некорректным.
Существует несколько наиболее известных видов ансамблирования:
\begin{itemize}
	\item Простое голосование 
	\begin{equation}
	b(x)=F(b_1(x),...,b_T(x))=\frac{1}{T}\sum_{t=1}^{T}b_t(x)
	\end{equation}
	,где $b_i$ -  некоторая функция.
	\item Взвешенное голосование 
	\begin{gather}
	b(x)=F(b_1(x),...,b_T(x))=\frac{1}{T}\sum_{t=1}^{T}w_tb_t(x)\\
	\sum_{t=1}^{T}w_t=1, w_t \geq 0
	\end{gather}
	,где $w_i$- некоторый коэффициент.
	\item Cмесь экспертов
	\begin{gather}
	b(x)=F(b_1(x),...,b_T(x))=\frac{1}{T}\sum_{t=1}^{T}w_t(x)b_t(x)\\
	\sum_{t=1}^{T}w_t=1, \forall x\in X
	\end{gather}
	,где $w_i(x)$- некоторая функция коэффициента.
\end{itemize}
Простое голосование - это  частный случай взвешенного голосования, а взвешенное голосование является частным случаем смеси экспертов. 

Различные методы ансамблирования такие как беггинг, бустинг, стекинг и другие применяются для улучшения работы алгоритмов обучения с учителем . Для алгоритмов обучения без учителя применяется простое голосование\cite{Book16}.
\subsection{Итеративный отбор}
Итеративный отбор основан на идее многократного применения алгоритмов ансамблирования. Преположим, построена некоторая модель, описывающая нормальные данные. Эта модель построена на основе всех  имеющихся данных, но точность этой модели невелика, она умеет определять только явные аномалии. Отсортировав все точки по показателю аномальности, можно выбрать k самых аномальных объекта в данных и исключить из данных. После этого можно перестроить модель и повторить вышеуказанные действия несколько раз, пока не будут достигнуты некоторые условия. При каждой итерации точность модели будет увеличиваться.

Идея итеративного отбора может быть обобщена различными способами. Результат работы одного алгоритма может быть использован для отсеивания явных аномалий и настройки нового алгоритма, не обязательно совпадающего с предыдущим, на оставшихся данных. Возможна и противоположная механика: по результатам работы одного алгоритма отбираются явные, гарантированные
представители нормальных данных, и исключительно на них строится модель, их описывающая.


\section{Результаты работы и обсуждение}
Можно улучшить алгоритм поиска аномалий путем используя один из вышеописанных подходов.
Например, новый метод будет заключаться в ансамблировании нескольких метрических методов. Было выбрано три метрических метода - метод K ближайших соседей, метод компонентного коэффициента выбросов, метод локального коэффициенты выбросов\cite{Book13}.
Для проверки работоспособности алгоритмов поиска аномалий на неразмеченных данных, эти алгоритмы проверялись на размеченных данных.
Для этого работа алгоритма поиска аномалий была протестирована на двух наборах данных\cite{datasets}:
\begin{table}[!h]
	
	\caption{\label{tab:issled1}Характеристики датасетов, метрики полноты и точности}
	
	\begin{center}
		
		\begin{tabular}{|l|l|l|l|l|l|}
			
			\hline
			
			Набор данных& Кол-во элем. & Кол-во атриб. &  Полнота & Точн.& Кол-во аном.  \\
			
			\hline 
			
			WBC& 453 & 9 & 0.99&0.94 & 10  \\
			
			\hline
			KDDCUP99 & 60853 & 41 & 0.93&0.06 & 246  \\
			\hline
			
			
		\end{tabular}
		
	\end{center}
	
\end{table}

\begin{table}[h]
	
	\caption{\label{tab:issled2}Сравнение  алгоритмов поиска аномалий}
	
	\begin{center}
		
		\begin{tabular}{|l|l|l|l|l|}
			
			\hline
			
			Алгоритм & AUC ROC WBC & F1 WBC &  AUC ROC KDD & F1 KDD \\
			
			\hline 
			
			LoOp& 0.98 & 0.72 & 0.68& 0.05  \\
			
			\hline
			ODIN & 0.62 & 0.80 & 0.80& 0.06  \\
			
			\hline 
			KDEOS & 0.25	 & 0.64 & 0.61& 0.05  \\
			
			\hline 
			LDOF & 0.64	 & 0.96 & 0.88&0.07  \\
			\hline 
			INFLO & 0.99	 & 0.9 & 0.98&0.29  \\
			\hline   
			Разр. алгоритм & 0.92	 & 0.97 & 0.93 & 0.06  \\
			
			\hline  
			
		\end{tabular}
		
	\end{center}
	
\end{table}
\begin{table}[h]
	
	\caption{\label{tab:issled2}Количество истинно/ложно позитивно/негативно классифицировавшихся}
	
	\begin{center}
		
		\begin{tabular}{|l|l|l|l|l|}
			
			\hline
			
			Набор данных & ИП & ЛП &  ИН & ЛН \\
			
			\hline 
			
			WBC & 10 & 18 & 425 & 0  \\
			\hline 
			
			KDDCUP99& 230 & 3603 & 57004& 16  \\	 
			
			\hline  
			
		\end{tabular}
		
	\end{center}
	
\end{table}
Проведем сравнения с другими алгоритмами поиска аномалий.
Как можно увидеть из результатов  метрик AUC ROC и F1, алгоритмы по-разному классифицируют  разные наборы данных.Например, алгоритм LoOP показывает высокий AUC ROC на первом наборе данных, но на втором наборе данных его показали значительно снижаются. В свою очередь, алгоритм ODIN показывает низкие результаты, по сравнению с остальными алгоритмами, на первом наборе данных, но на втором наборе данных его AUC ROC высок. Разработанной алгоритм показывает средние значения AUC ROC, но высокие значения показателя F1, что позволяет утверждать, что этот алгоритм жизнеспособен и возможно его применение на определенных наборах данных. 




\section{Заключение}
Задача поиска аномалий достаточно нетривиальна, а способы её решения могут сильно различаться в зависимости от характектеристик данных и цели поиска. В отсутствии предварительно размеченных данных применяют алгоритмы обучения без учителя. Наиболее универсальным классом таких методов явлются метрические методы. Их легко комбинировать между собой, а также они не требуют наличия априорной информации о данных. Т.е их использование является наиболее универсальным подходом.

Предложен новый метод поиска аномалий заключающийся в ансамблировании простым голосованием трех метрических методов: K ближайших соседей, компонентного коэффициента выбросов, локального коэффициента выбросов. Сравнение нового метода с уже существующими  показало выигрыш до 30\% по метрикам AUC ROC и F1 на наборах данных с количеством аномалий не более 1\% от общего числа элементов и не менее чем 0.1\%.

Метод имеет свои особенности, в частности тендецию к нахождению ложно позитивных результатов. Количество ложно позитивных значений может достигать 5\%. Однако, количество ложно негативных значений крайне мало(менее 0.1\%). Поэтому метод рекомендуется использовать в задачах, где акцент делается на нахождении позитивных значений.



