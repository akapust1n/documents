\chapter{Конструкторский раздел}
В этом разделе приводится подробное описание разрабатываемого метода, выделяются основные его компоненты, описываются метрики, оценивающие метод. 
В выводе аналитической части предлагается разработать новый метод прогнозирования результатов теннисных матчей. Новый метод будет включать в себя построение модели на основе численных статистических данных, а так же текстовых данных.

\begin{figure}[!h]
	\centering
	\includegraphics[width=.9\textwidth]{diagrams/img/main_img_cut.png}
	\caption{Общая схема программного комплекса}
	\label{fig08}
\end{figure}
\section{Обработка текстовых данных}
Работа осуществляется с текстами только на английском языке.
Для того чтобы использовать преобразовать текстовые данные в числовое представление, нужно выполнить следующие действия:

\begin{itemize}
	\item Удалить все нерелевантные символы (например, любые символы, не относящиеся к цифро-буквенным).
	\item Токенизировать текст, разделив его на индивидуальные слова.
	\item Удалить нерелевантные слова — например,  гиперссылки.
	\item Перевести все символы в нижний регистр для того, чтобы слова «привет», «Привет» и «ПРИВЕТ» считались одним и тем же словом.

	\item Произвести лемматизацию, т. е. сведения различных форм одного слова к словарной форме (например, «машина» вместо «машиной», «на машине», «машинах» и пр.)
	\item Удалить слова, не несущих самостоятельной смысловой нагрузки. Например, артиклей в английском языке.
	\item Произвести стемминг текста, т.е. заменить исходные слова их основами.

\end{itemize}


\section{Определение тональности текста}
Используем численную метрику тональности текста для её добавления в численный набор данных. Для этот используем вышеописанный метод word2vec с алгоритмом CBOW с размером контекста 1.
\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.5]{master_img/cbow_model2.png}
	\caption{Архитектура нейронной сети word2vec CBOW с размером контекста 1}
	\label{fig09}
\end{figure}
 Первоначально каждое слово в словаре – случайный N-мерный вектор. Во время обучения алгоритм формирует оптимальный вектор для каждого слова с помощью метода CBOW. После обучения модели на размеченных данных на выходе получаем обученную модель. Использование модели для анализа конкретного слова даёт на выходе некоторый вектор значений фиксированного размера.
 
 Далее для объединения близких по смыслу слов используется кластеризация.Используем алгоритм кластеризации К-средних: пусть  имеется определенное количество кластеров N, алгоритм обучаясь на тренировочных данных делит их на кластеры и находит центры каждого из них, затем при входе тестовых данных, алгоритм присваивает ему номер кластера, центр которого ближе всех к нему. После этого каждое слово заменяется индексом кластера. В данной работе количество кластеров будет зависеть от полученного словаря слов, количество кластеров будет равняться размерности словаря поделенной на 5\cite{Book31}.
Таким образом текст будет преобразован в вектор чисел и можно приступить к оценку его тональности.

Используем алгоритм случайного леса(англ. random forest) для оценки тональности текста. В итоге для текста получаем некоторое, которая оценивает его тональность.
Для обучения нейронной сети используется набор данных предматчевых интервью спортсменов.

\section{Нормализация данных}
Полученный набор оценок для каждого текста, а так же все статистические свойства нормализуем при помощи min-max нормализации по формуле\ref{mixmaxNorm}.
\section{Выбор оптимального набора параметров}
В нашем набора данных имеется набор статистических параметров, выберем из них N наиболее значимых параметров при помощи фильтр-метода хи-квадрата\ref{chi2}.
В нашем датасете имеется Y следующих параметров:
\begin{itemize}
	\item рейтинг ATP
	\item Процент выигрыша очков на приеме 1-ой подачи
	\item Процент выигрыша очков на приеме второй подачи
	\item Процент успешной первой подачи
	\item Процент выигрыша брекпойнтов
	\item Процент успешно отбитой первой подачи
	\item Проценты выигрыша очков на второй подаче
	\item Процент спасения брейкпойнтов
	\item Процент проигрыша брейкпойтов
	\item Количество эйсов
	\item Процент выигрыша очков на первой подаче
	\item Количество выигранных первых подач
	\item Количество выигранных вторых подач
	\item Количество выигранных приемов первой подачи
	\item Количество выигранных приемов второй подачи
\end{itemize}

Из этого набора признаков необходимо выделить N оптимальных свойств(на правила данный момент для выбора оптимальных количествой свойств являются открытым вопросом в современной науке\cite{Book32}), поэтому оптимальное количество слов подбирается эмпирическим путем).
\section{Прогнозирование результатов}
В нейронную сеть на вход подаются нормализованные статистические данные, совмещенные с текстовыми данными. Текстовые данные переведены в численный вид и нормализованы.
Нейронная сеть для прогнозирования результатов теннисных матчей имеет следующие параметры параметры:
\begin{itemize}
	\item Количество слоёв - 3, из них 2 скрытых.
	\item Количество нейронов на каждом слое: 64->32->1
	\item Функции активации по слоям:
	 линейный выпрямитель(англ. relu)->линейный выпрямитель->сигмоида
\end{itemize}
\begin{lstlisting}[language=python,,escapeinside={(@}{@)},caption={Псевдокод нейронной сети для осуществления прогнозов}] 

network = models.Sequential()
network.add(layers.Dense(units=64, activation='relu', input_shape=(len(features.columns),)))
network.add(layers.Dense(units=32, activation='relu'))
network.add(layers.Dense(units=1, activation='sigmoid'))

network.fit(train_features, train\_target, 
epochs=1000, verbose=0, batch\_size=128, 
validation_data=(test_features, test_target), callbacks=[es, mc]) 

\end{lstlisting}