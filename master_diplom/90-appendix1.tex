\chapter{Приложение А}
\label{cha:appendix1}

%\begin{figure}
%\centering
%\caption{Картинка в приложении. Страшная и ужасная.}
%\end{figure}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "rpz"
%%% End: 
%,caption={Код создания модели Word2Vec},
\captionsetup{justification=centering}

\begin{lstlisting}[language=python,,escapeinside={(@}{@)}, xleftmargin=.1\textwidth, xrightmargin=.1\textwidth] 
import gensim
from sklearn.model_selection import train_test_split
from sklearn.linear_model import SGDClassifier
from gensim.models.word2vec import Word2Vec
from sklearn.preprocessing import scale
from sklearn.calibration import CalibratedClassifierCV

import numpy as np
import os
import random
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
from clText import cleanText

data_path = "data/"
pos_files = os.listdir(data_path + "pos/")
neg_files = os.listdir(data_path + "neg/")

for pos_file in pos_files:  
	with open(data_path + "pos/" + pos_file, 'r') as infile:
	pos_reviews = infile.readlines()

for neg_file in neg_files:
	with open(data_path + "neg/" + neg_file, 'r') as infile:
	neg_reviews = infile.readlines()

y = np.concatenate((np.ones(len(pos_reviews)), np.zeros(len(neg_reviews))))

x_train, x_test, y_train, y_test = train_test_split(
np.concatenate((pos_reviews, neg_reviews)), y, test_size=0.2)

x_train = cleanText(x_train)
x_test = cleanText(x_test)

n_dim = 300

imdb_w2v = Word2Vec(size=n_dim, min_count=10)
imdb_w2v.build_vocab(x_train)

imdb_w2v.train(x_train, total_examples=imdb_w2v.corpus_count,
epochs=imdb_w2v.iter)



\end{lstlisting}
