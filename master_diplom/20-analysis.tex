\chapter{Аналитический раздел}
\label{cha:analysis}
\section{Цель и задачи работы}
Целью данной работы является создание метода прогнозирования результатов теннисных матчей на основе априорной информации.
Для достижения данной цели необходимо решить следующие задачи:
\begin{itemize}
	
\item проанализировать предметную область и существующие методы прогнозирования результатов теннисных матчей
	\item разработать метод прогнозирования результатов теннисных матчей
	\item создать ПО, обрабатывающее данные для анализа
	\item создать ПО, реализующее  разработанный метод прогнозирования результатов теннисных матчей
\end{itemize}
\section{Что такое спортивное прогнозирование}
Спортивное прогнозирование предполагает предугадывание результатов предстоящих спортивных событий или контрольных результатов, которые спортсмен) или команда спортсменов) показывает на спортивных соревнованиях\cite{Book01}. Прогнозы даются на конкретные события в конкретные моменты времени,на результат совокупности событий,ограниченных во времени(например, соревновательный сезон). Наиболее распространены прогнозы на результаты конкретного матча и сезона в целом. Прогнозы могу осуществляться на основе алгоритмов анализа информации, экспертной оценке, а так же комбинацией экспертной оценки. В данной работе будет рассмотрено прогнозирование на основе анализа априорной информации. Т.е. прогноз на какое-либо событие будет даваться до его начала и текущая информация о ходе события не будет учитываться.
\section{Сложность прогнозирования результатов}
 Большинство исследователей используют различную статистическую информацию для составлении прогнозов. Из массива накопленных данных они выбирают небольшое количество набиболее важных показателей(или же останавливаются только на одном из них) за ограниченный промежуток времени, которые подаются на вход алгоритму.
 Какие показатели считать значитыми определяет автор алгоритма на основе экпертной оценки или каких-то дополнительных алгоритмов "отбора наиболее важных показателей\".
 Например, в случае американского футбола\cite{Book02} это могут быть
 \begin{enumerate}
 	\item  Время владения мячом
 	\item Проводился ли матч дома или в гостях
 	\item Общее количесто ярдов
 	\item Разница в атакующих ярдах
 	\item Количество потерь мяча
 \end{enumerate}
Или же в случае баскетбола, например, может браться следующий набор показателей:
 \begin{enumerate}
	\item  Количество травмированных игроков
	\item Количество выигранных матчей подряд перед данной игро
	\item Усталость команды. Показатель считается на основе расстояния, которое пришлось преодолеть команде, чтобы провести последние 7 игр
	\item Средний домашний, гостей и общий процент побед
	\item Рейтинг команды в "рейтинге нападения", "рейтинге защиты" и "общем рейтинге"(подробнее методики подсчёта рейтингов описываются в \cite{Book03})
\end{enumerate}
Большая часть статей представляет команду как некое единое целое, упуская из виду каждого игрока команды. Учёт информации каждом игроке - нетривиальная задача.
Поэтому для упрощения создания алгоритма прогнозирования с учётом каждого игрока команды был выбран вид спорта - одиночный теннис. В каждой команде по одному игроку, два возможных исхода матча - победа или поражения.
% тут явно можно написать больше про
\section{Основные правила игры в теннис}
Ниже приведнены основные правила, которые могут повлиять на составление алгоритмов прогнозирования. С полной версии правил можно ознакомится на сайте международной теннисной федерации\cite{Book04}.
 \begin{enumerate}
	\item  Мяч должен приземлиться в пределах теннисного поля, чтобы продолжить игру. Если игрок мяч приземляется за пределами поля, то это приводит к потере им очков.
	\item Игроки не могут дотронуться до сетки или перейти на сторону противника
	\item Игроки не могут носить мяч или ловить его ракеткой
	\item Игроки не могут дважду ударить по мячу
    \item Игрок должен дождаться пока мяч пересечёт сетку, прежде чем ударить по нему
    \item Игрок, который не возвращает мяч на половину поля противника, преждне чем он отскочит дважды, считается проигравшим
    \item Если мяч ударяет или касается игроков, то это карается штрафом
    \item Перед тем как отбить подачу, мяч должен отскочить от поля.
    \item Очки -наименьшая единица изменрения.Приращение очков идёт в формате 0-15-30-40-гейм.
    \item Гейм состоит из 4 очков и выигрывается, когда игрок набирает 4 очка с преимуществом не менее двух очков.
    \item Сет состоиз 6 геймов и выигрывается игроком, который набирает 6 геймов 
 	 с минимальным отрывом в 2 очка.
 	 \item Дополнительный сет - сет, который разыгрывается при достижении игроками счёта 6-6 по геймам. При
  	\item Максимальное количество сетов в матче может достигать 3 или 5. По достижении 2 или соотвественно 3 выигранных сетов матч заканчивается.
  	\item "Ровно"\ происходит когда достигнут счёт по очкам 40-40. Чтобы выиграть гейм, игрок должен выиграть два последовательных очках. Если игрок выигрывает одно очко, то счёт в гейме становится "больше"\, но если он теряет следующее очко, то счёт возвращается к "ровно"\ .
  	\item Когда в гейме достигнут счёт 6-6, то играется тай-брейк. В розыгрыше тай-брейке используются особые правила набора очка. Победителей считается игрок, набравший не менее 7 очков с преимуществом два очка над оппонентом.
\end{enumerate}
\section{Основные подходы прогнозирования теннисных матчей}
Существует три основных подхода к прогнозированию теннисных матчей: методы попарного сравнения, методы вычисления очков и методы машинного обучения.
\subsection{Метод подсчёта очков}
Методы вычисления очков(также их называют иерархическими методами) фокусируются на оценке вероятности выигрыша каждого очка в матче. 
% P. K. Newton and J. B. Keller
В этом подходе предполагается, что достаточно знать вероятность выигрыша игроком А $p_a^r$ очка на своей подаче и вероятность выигрыша очка игроком B на своей подаче $p_b^r$. Аналогичные подходы  применяются при подсчете вероятности выигрыша игрока в бадминтоне\cite{Book19} и сквоше\cite{Book20}.Впервые такой метод был применен к теннису в работах Кси и Бюрича\cite{Book21}, Картера и Крю\cite{Book22}, Полларда\cite{Book05}.
Такие работы одинаково определяют вероятность выигрыша очка в матче как равномерную случайную величину, т.е. вероятности  $p_a^r$ и  $p_b^r$ принимаются за постоянные величины на протяжении всего матча. Анализ статистических показателей показывает, что такое предположение допустимо\cite{Book06}, т.к. отклонения от ожидаемой величины невелики.
\subsubsection{Вероятность выиграть гейм}
Игрок А может выиграть гейм у игрока В со счётом [4,0], [4,1],4,2] в случае если игрок А выиграл 4 очка за гейм, а игрок В выиграл не более двух. Если же счёт в гейме стал [3,3], то такая ситуация называется "ровно"\ . В этом случае игрок A может выиграть гейм, закончив его с итоговым счетом [n + 5, n + 3], где $n\geq0$. Чтобы посчитать вероятность $p_G^R$ выигрыша игроком А гейма на своей подаче, введем следующие обозначения: $p_A^R$ - вероятность выигрыша очка на своей подаче игроком А, $q_A^R=1-p_a^R$, $q_A^G = 1 - p_A^G$, $p_A^G(i,j)$ - вероятность того, что i очков в гейме наберет игрок А, а j очков в гейме наберет игрок B. В результате получим следующую формулу:
\begin{equation}
p_A^G=\sum\limits^{2}_{j=0}{p_A^G(4,j)  + p_A^G(3,3)\sum\limits^{\inf}_{n=0}p_a^{DG}(n + 2, n)}
\end{equation}
Пусть $p_A^{DG}(n + 2, n)$ - вероятность того, что игрок А выиграет с преимуществом в 2 мяча после того как был достигнут счет [3,3] на подаче игрока А.
\begin{equation}
p_A^{DG}(n+2,n)=\sum\limits^{n}_{j=0}{(p_A^Rq_A^R)^j(q^R_Ap^R_A)^{n-j}\frac{n!}{j!(n-j)!}}(p^R_A)^2=(p^R_A)^2(p^R_Aq^R_A)^n2^n
\end{equation}

В результате из формул 1 и 2 можно вывести следующую формулу -  вероятность выигрыша игроком А гейма на своей подаче.
\begin{equation}
p_A^{G} = (p^R_A)^4(1 + 4q^R_A + 10(q^R_A)^2) + 20(p^R_Aq^R_A)^3(p_A^R)^2(1 - 2_A^Rq^R_A)^{-1}
\end{equation} 
К
\subsubsection{Вероятность выиграть сет}
Пусть $p_A^S$ - вероятность того, что игрок А выиграет сет у игрока В, если игрок А начинает подавать первым, $q_A^S=1 - p^S_A$. Чтобы вывести $p^G_A$ из $p^G_A$ и $p^G_B$, определим $p_A^S(i,j)$ как вероятность того, что в розыгрыше сета игрок А выиграет i геймов, игрок B j геймов . Тогда
\begin{equation}
p_A^S=\sum\limits^{4}_{j=0}{p_A^S(6,j)} + p^S_A(7,5) + p^S_A(6,6)p^T_A\label{eq1}
\end{equation}
Где $p^T_A$  вероятность того, что игрок А выиграет 13-очковый тай-брейк , начинающийся с подачи игрока А.
\subsubsection{Вероятность выиграть матч}
Пусть $p^M_A$ - вероятность того, что игрок А выиграет матч у игрока B. Определим $p_{AB}^M(i,j)$ как вероятность, что игрок а выиграет в матче после того как количество выигранных им сетов достигнет i, а количество выигранных сетов у игрока B будет j, где матч начинается с подачи игрока А, а заканчивается на подаче B. Аналогично - $p^M_{AA}$.

Аналогично зададим вероятности победы для сетов $p^S_{AB}, p^S{AA}, p^S_{BA}, p^S_{BB}$, где $P^S_{XY}$ - вероятность того, что игрок сет закончится выигрышем игрока Х, начинающийся с подачи Х и заканчивающийся на подаче У.
Очевидно, что количество разыгранных геймов для $p^S_{XX}$ будет нечетным. Ограничим формулу \eqref{eq1}
\begin{equation}
p_A^S=\sum\limits_{j=1,3}{p_A^S(6,j)}  + p^S_A(6,6)p^T_A
\end{equation}

Если игрок Х подает в первом сете матча, а Y в последнем, количества геймов в сете будет нечетным.
Преобразуем \eqref{eq1}.
\begin{equation}
p_A^S=\sum\limits_{j=0,2,4}{p_A^S(6,j)} + p^S_A(7,5) 
\end{equation}

Итоговая формула для матчей где для достижения победы надо первым выиграть 3 сета(матчи мужского тенниса), будет выглядеть следующим образом(с более детальным выводом формул можно ознакомиться в \cite{Book05}, \cite{Book06}).
\begin{equation}
p_A^M=\sum\limits^{2}_{j=0,2,4}{(p^M_{AA}(3,j) + p^M_{AB}(3,j))} 
\end{equation}
Для матчей до 2 выигранных сетов(женский теннис)
\begin{equation}
p_A^M=\sum\limits^{1}_{j=0}{(p^M_{AA}(2,j) + p^M_{AB}(2,j))} 
\end{equation}
\subsection{Методы попарного сравнения}
Основная идея методов попарного сравнения заключается в том, что каждого игроку присваивается некий положительный рейтинг, который характеризует уровень его навыков. Эти методы основаны на алгоритме, предложенном Бредли-Терри\cite{Book17} и адаптированном для тенниса Ианом МакХолом\cite{Book18}.
Основная идея заключается в том, что вероятность победы игрока А над игроком B рассчитывается как
\begin{equation}
p_A=\frac{\alpha_A}{\alpha_A + \alpha_B}\label{eq2}
\end{equation}
Где $\alpha_A$ - рейтинг игрока А, а $\alpha_B$ - игрока В. Вариативность алгоритмов данного класса достигается за счёт различных методик подсчёта этого рейтинга. Например, при помощи ЭЛО-рейтинга\cite{Book09}. Рассмотрим один из вариантов - подсчёт рейтинга, основанный на количестве выигранных геймов. Преимуществом этого метода является, тот факт, что берется в расчёт информация о ходе матча. Т.е. разница между матчам проигранным со счётом 6-0,6-0 и со счётом 7-6, 7-6 существенна.
Тогда вклад можно оценить по следующей формуле
\begin{equation}
p^M_A=L(\alpha_A,\alpha_B) ∝\frac{\alpha_A^{g_a}\alpha_b^{g_b}}{(\alpha_A + \alpha_B)^{g_A + g_B}}
\end{equation} 
где $g_A$-количество выигранных геймов игроком А, а $g_B$ -  игроком В(тай-брейк  считается за обычный гейм).
Приведем формулу для расчёта рейтинга игрока из одной из последних работ, посвященной данному классу методов
\begin{equation}
% Z = A
L(\alpha_a(t,); a=1,...n) = \prod_{k\in Z_t}(\frac{\alpha_a(t,S)^{g_A} + \alpha_B(t,S)^{g_B}}{(\alpha_A(t,S) + \alpha_B(t,S))^{g_A + g_B}})^{exp(\epsilon( t-t_k))S_k}
\end{equation}
Где t - время матча на поверхности теннисного корта S, k - индекс сыгранного матча, $t_k$ - продолжительность матча k, $Z_t={k : < t_k < t}$, n - количество игроков в моделе, $\epsilon$ - параметр зависящий от S.

\subsection{Машинное обучение}
Машинное обучение - это область искусственного интеллекта (ИИ), которая изучает алгоритмы, которые обучаются на основе данных.
Алгоритмы машинного обучения с учителем ставят свой задачей вывести получить функцию пребразования данных из помеченных данных, где помеченные данные представляют собой пары : вектор значений  - результат.
В теннисе обычно используют исторические данные для формирования данных для обучения. Например, вектор значений может содержать информацию о матче и игроках, а результатом соотвественно будет служить исход матча. Выбор оптимальных параметров для формирования вектора напрямую влияет на точность получаемой функции.
К проблеме прогнозирования теннисных матчей можно подойти двумя способами:
\begin{itemize}
	\item Регрессионный подход, где результатом будет являться дейтвительное число - вероятность выиграть матч. Вероятности выиграть матч неизвестны для исторических данных, что вынуждает помечать их в исторических данных метками 0 и 1.
	\item Подход бинарной классификации. Тогда результатом работы алгоритма будет предсказание выигрыша или проигрыша матча.
\end{itemize}
\break
\subsubsection{Логистическая регрессия}
Несмотря на своё названия, логистическая регрессия является алгоритмом классификации. Свойства логической функции являются ключевыми для алгоритма. Логистическая функция определяется как:
\begin{equation}\label{formula3}
\sigma=\frac{1}{1 + e^{-t}}
\end{equation}
Логистическая функция отображает 
вещественные числа в диапазоне $(-\inf, +\inf)$ в диапазон $[0,1]$. Выходное значение логистические функции может интерпретироваться как вероятность.

Логистическая регрессия для прогнозирования матчей состоит из N свойств $x=(x_1,x_2, ..., x_n)$ и вектора
n+1 вещественных параметров модели $\beta=(\beta_0,\beta_1,...,\beta_n)$. Чтобы сделать прогноз при помощи модели, нужно преобразовать точке в n-мерном пространстве свойств  в вещественной число
\begin{equation}
z=\beta_0 +\beta_1x_1+\beta_2x_2+...\beta_nx_n
\end{equation}
Подставляя z в формулу \ref{formula1} получим 
\begin{equation}\label{formula1}
p=\sigma(z)=\frac{1}{1 + e^{-z}}
\end{equation}
Обучение модели состоит в оптимизации параметров $\beta$, таким образом, чтобы модель "как можно точнее" воспроизводила результаты матчей из данных для обучения. Это делается при помощи минизации функции логистических потерь \ref{formula2}, которая показывает меру ошибку прогнозирования результатов матчей тренировочных данных.
\begin{equation}\label{formula2}
L(p)=\frac{-1}{N}\sum_{i=1}^Np_ilog(y_i) + (1 - p_i) + (1 - p_i)log(1-y_i)
\end{equation}
Где N - количество матчей в обучающих данных, $p_i$ - предсказанная вероятность выиграть матч i,  $y_i$ - фактический исход матча(0 - поражение, 1 - победа).

 В зависимости от размера датасета, выбирается одна из двух функций минимизации:
 \begin{itemize}
 	\item Стохастический градиентный спуск - медленный итеративный метод, подходящий для больших датасетов
 	\item Метод максимального правдоподобия - быстрый численный метод, не подходящий для работы с большими датасетами.
 \end{itemize}
Большинство публикаций, в которых используется методы машинного обучения для прогнозирования теннисных матчей, используют логистическую регрессию. Например, Кларк и Дит\cite{Book10} построили логистическую регриссионную модель, основанную на разнице набранных очков в рейтинге ATP для прогнозирования результатов розыгрыша сета. Другими словами, они использовали одномерную регрессию x=(разница\_в\_рейтинге) и оптимизировали $\beta$ таким образом, чтобы функция $\sigma(\beta_1x)$ показала наилучший результат на обучающем датасете.Параметр $\beta_0$ был исключён их модели на основании того, что разница в рейтинге 0 может давать вероятность выигрыша матча 0.5. Вместо того, чтобы прогнозировать результаты матча, они предпочли предсказывать результаы каждого конретного сета, тем самым увеличивая набор данных для обучения.

Ма, Лу и Тан\cite{Book11} использовали многомерную регрессию, использующую 16 свойств, поделённых на 3 категории: умения игрока, характеристики игрока и характеристики матча. Модель была обучена на матчах между 1991 и 2008 годом и была использована для улучшения тренировок игроков.

Логистическая регрессия привлекает исследователей тем, что она позволяет быстро обучать модели, почти не влечёт проблем переобучения моделей, а так же позволяет получить легко интерпретируемый выходной параметр - вероятность выиграть матч. Тем не менее, при наличии сложных взаимосвязей между входными параметрами, использование логистической регрессии может стать нетривиальной задачей.

\subsubsection{Нейронные сети}
Искуственная нейронная сеть - это система взаимосвязанных "нейронов"\, вдохновлённая биологическими нейроннами. Каждый нейрон преобразует входные данные в какое-то выходное значение, которое в дальнейшем могут быть использованы в качестве входных данных для других нейронов. Нейронная сеть обычно имеет несколько слоёв,c нейроном на каждом не-входном слое, соединённом с нейронами в предыдущих слоях.
\begin{figure}[!h]
	\centering
	\includegraphics[width=.9\textwidth]{img/img1.png}
	\caption{Трехслойная нейронная сеть с прямыми связями(ПЕРЕВЕСТИ КАРТИНКУ)}
	\label{fig01}
\end{figure}
Каждая связь в сети имеет свой вес. Нейрон использует входные значения и веса чтобы посчитать выходное значение. Типичным методом композиции является  взвешенная сумма.

\begin{equation}
f(x)=K(\sum_iw_ix_i)
\end{equation}
Нелийнейная функции активации К позволяет нейронной сети решать нетривиальный задачи, используя небольшое количество нейронов. Логистическая функция \ref{formula3} может использоваться в качестве функции активации.

Прогноз результата матча осуществляется на основе передачи в нейронную сеть неких свойств игрока и свойств матча. Если используется логичестическая функция активации, то выходное значение нейронной сети можно интерпретировать как вероятность выиграть матч. Есть большое количество различных алгоритмов обучения, которые оптимизируют набор весов нейронной сети в целях получении наилучшего выходного значения. Например, алогритм обратного распространения использует градиентный спуск для уменьшения среднего квадрата ошибки между целевыми значениями и выходами сети.

Например, Сомбоонфокафан\cite{Book12} сконструировал трёхлойную сеть прямой связи, использую алгоритм обратного распространения ошибки. Протестировал на различных архитектурах сети и различных наборах свойств. Нейронная сеть, показавшая наилучший результат, имеет 27 входных нейронов. На вход подавались свойства, описывающие обоих игроков, а так же свойства матча. В результате была получена точность предсказания 75\% на исторических данных турниров "Большого шлема"\ в 2007-2008 годах.

Нейронная сеть можно установить наличие сложных взаимотношений между различными свойствами, подаваемыми на вход. Но она работает по принципу "черного ящика"\, т.е. механизм определения таких взаимоотношений не будет известен. К недостаткам нейронных сетей так же можно отнести то, что они склонны к переобучению, зачастую требует большого количества данных для обучения. Кроме того, разработка структуры сети зачастую является эмпирической и выбор гиперпараметров модели часто идёт методом проб и ошибок.
\subsubsection{Метод опорных векторов}
Основная идея метода опорных векторов заключается перевод исходных наборов свойств  в пространство более высокой размерности и поиск разделяющей гиперплоскости с максимальным зазором в этом пространстве. Две параллельных гиперплоскости строятся по обеим сторонам гиперплоскости, разделяющей классы. Разделяющей гиперплоскостью будет гиперплоскость, максимизирующая расстояние до двух параллельных гиперплоскостей. Алгоритм работает в предположении, что чем больше разница или расстояние между этими параллельными гиперплоскостями, тем меньше будет средняя ошибка классификатора.
На данный момент в открытом доступе нет работ по прогнозировани теннисных матчей при помощи метода опорных векторов\cite{Book13}. Метод опорных векторов имеет несколько преимуществ по сравнению с нейронными сетями. Во-первых, обучение не заканчивается на локальном минимуме, что зачастую бывает с нейронными сетями. Во-вторых, при наличии большого количество данных для обучения, метод опорных векторов обычно превосходит нейронные сети в прогнозировании \cite{Book13}. Тем не менее, время обучения модели метода опорных векторов намного выше, а создание и задание необходимых параметров модели является нетривиальной задачей.

\subsubsection{Проблемы машинного обучения}
Наличие большого количества данных для обучения не означает получение более точных результатов прогнозирования результатов теннисных матчей, т.к. большое количество данных означает, что теннисист играл много лет матчи. Со временем его навыки меняются и результаты последних матчей представляют набольший интерес. Так же в теннисе важную роль играет покрытие на которой играется матч, т.е. для модели необходимы данные о последних матча игрока именно на этом покрытии. Поэтому машинное обучение может страдать от недостатка данных, что может приводить к переобучению модели, с которым может быть сложно бороться. В частности нейронные сети сильно подвержены переобучению если количество слоёв/нейронов сравнительно велико относительно размера данных для обучения.

Чтобы бороться с проблемой переобучения, нужно использовать только важные свойства для обучения. Процесс отбора важный свойств набора данных называется "отбор признаков"\, для этого существует большое количество различных алгоритмов. Удаление незначащих свойств значительно уменьшает время обучения
\subsubsection{Оптимизация гиперпараметров}
Модель имеет параметры как полученаемы в процессе обучения путём их оптимизации(например, веса в нейронных сетях), так и статически задаваемые параметры такие как количество скрытых слоёв, количество нейронов в каждом слоё. Статически настраиваемые параметры назвают гиперпараметрами. Процесс получения оптимальных гиперпараметров может быть как эмпирическим, так и алгоритмическим. Пример алгоритмического поиска гиперпараметров - поиск по сетке. Он происходит на заранее определённом пространстве гиперпараметров. Для построения модели прогнозирования с высокой точностью, необходимо тщательно подобрать необходимые гиперпараметры.

\subsubsection{Выбор оптимальных свойств}
Каждый набор данных может содержать большое количесто различных свойств. Каждое свойство вносит определенный вклад в итоговый результат. Выбор оптимального количества наиболее значимых свойств - приём очень часто применяемый в машинном обучение. От количества свойств зависит производительность получаемой модели. Свойства, не влияющие на итоговый результат, или влияющие незначительно, негативно влияют на производительность модели, при влючении их в оную. Так же нерелевантные свойства могут ухудшуить точность модели, заставить её обучаться на нерелевантных данных\cite{Book14}.

Преимущества выбора оптимального набора свойства
\begin{itemize}
	\item Уменьшаеть вероятность переобучения. Испольнование меньшего количества избыточных данных уменьшает вероятность принятия решения на основе "шума"\ .
	\item Повышение точности.
	\item Сокращает время обучения- меньшее количество данных снижают сложность модели.
\end{itemize}
Выбор свойств может производится как в ручном, так и автоматическом режиме.

Существуют 3 основных класса алгоритмов выбора свойств.
\begin{itemize}
\item Фильтр. Рассчитывается определенная метрика и свойства "фильтруются" на основании этой метрики
\item Обертка. "Оберточные"\ методы рассматривают выбор оптимального набора свойств
\end{itemize}

\textbf{Корреляция Пиросона} - фильтр-метод, который использует в качестве метрики следующую формулу:
\begin{equation}
r=\frac{\sum(x - \overline{x})(y - \overline{y})}{\sqrt{\sum(x - \overline{x})^2\sum(y - \overline{y})^2}}
\end{equation}

\textbf{Хи-квадрат метод} - фильтр-метод, который использует в качестве метрики следующую формулу:
\begin{equation}
\chi^2=\sum_{i=1}^n\frac{(O_i - E_i)^2}{E_i}
\end{equation}
Где $O_i$ - фактическое количество наблюдений класса i, а $E_i$ - ожидаемое количество наблюдей класса i, при условии отсутствия зависимости между свойством и ожидаемым значением.
Рассмотрим пример подсчёта метрики Хи-квадрат.
Предположим, у нас есть следующие данные
\begin{table}[!h]
	
	\caption{\label{tab:table1}Фактическое количество наблюдений результатов игроков}
	
	\begin{center}
\begin{tabular}{|l|l|l|l|}

\hline

  & Кол-во побед & Кол-во поражений & Всего \\
\hline
Игрок1  & 20 & 5 & 25 \\
\hline
Игрок2  & 40 & 35 & 75 \\
\hline
Всего  & 60 & 40 & 100 \\
\hline

\end{tabular}
		
\end{center}

\end{table}

Для того чтобы посчитать значения $\chi^2$, посчитаем "ожидаемое"\ значение в каждой ячейки, если бы свойства были дейтвительно независимы. Для этого нужно просуммировать значения каждой строки и поделить на общее количество записей.
Получим следующую таблицу;
\begin{table}[!h]
	
	\caption{\label{tab:table2}Ожидаемое количество наблюдений результатов игроков}
	
	\begin{center}
\begin{tabular}{|l|l|l|l|}

\hline

  & Кол-во побед & Кол-во поражений & Всего \\
\hline
Игрок1  & 15 & 10 & 25 \\
\hline
Игрок2  & 45 & 25 & 75 \\
\hline
Всего  & 60 & 40 & 100 \\
\hline

\end{tabular}
		
\end{center}

\end{table}

\textbf{Лассо-метод(сокращение от англ. least absolute shrinkage and selection operator)} - встроенный метод. На основе линейной регрессии происходит пошаговый выбор оптимальных параметров модели.  Идея метода заключается в том, что накладывается ограничение на сумму абсолютных значений свойств модели, сумма должна быть меньше некоторого фиксированного значения. Для этого того, чтобы этого добиться, применяется методы сжатия(регуляризации), в процессе которого коэффициенты регрессионных переменных уменьшаются. Свойства, получившие в результате регуляризации нулевой коэффициент, отбрасываются.

\textbf{Методы на основе деревьев} относятся к классу встроенных методов. Например, для определения оптимального наборы свойств может использоваться алгоритму случайного леса. Принцип работы встроенных методов нетривиален и выходит за рамки данной работы, подробнее с их принципами работы можно ознакомится в \cite{Book15}
